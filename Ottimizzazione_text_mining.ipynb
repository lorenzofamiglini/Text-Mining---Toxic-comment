{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "config = tensorflow.compat.v1.ConfigProto() \n",
    "config.gpu_options.allow_growth = True\n",
    "config.log_device_placement = True\n",
    "sess = tensorflow.compat.v1.Session(config=config)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv1D, MaxPool1D, GlobalMaxPool1D, Embedding, Activation\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow.keras as ks\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.initializers import Constant\n",
    "from tensorflow.keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"D:\\Datasets\\NLP_text_mining\\preprocessed_text_toxic2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\loren\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras_preprocessing\\text.py:178: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
      "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 184883 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(nb_words=100000)\n",
    "tokenizer.fit_on_texts(df['text'].astype(str))\n",
    "sequences = tokenizer.texts_to_sequences(df['text'].astype(str))\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "data = pad_sequences(sequences, maxlen=100)\n",
    "\n",
    "labels = to_categorical(np.asarray(df.toxic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into a training set and a validation set\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "nb_validation_samples = int(0.20 * data.shape[0])\n",
    "\n",
    "x_train = data[:-nb_validation_samples]\n",
    "y_train = labels[:-nb_validation_samples]\n",
    "x_val = data[-nb_validation_samples:]\n",
    "y_val = labels[-nb_validation_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# load the whole embedding into memory\n",
    "embeddings_index = dict()\n",
    "f = open(\"D:/Datasets/embeddings/glove.6B.200d.txt\", encoding=\"utf8\")\n",
    "lista = []\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    lista.append(word)\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, 200))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "train_img_pro = ImageDataGenerator()\n",
    "def balanced_flow_from_directory(flow_from_directory):\n",
    "    for immagini, classi in flow_from_directory:\n",
    "         yield custom_balance(immagini.reshape(immagini.shape[0],immagini.shape[1]),classi)\n",
    "            \n",
    "def custom_balance(X, y):\n",
    "    rus = RandomUnderSampler()\n",
    "    X_resampled, y_resampled = rus.fit_sample(X, y.argmax(axis = -1))     \n",
    "    #X_resampled, y_resampled = shuffle(X_resampled, y_resampled)\n",
    "    #y_resampled = y_resampled.reshape(y_resampled.shape[0], 1, 1, 1) #da mettere se uso model_conv()\n",
    "    y_resampled = to_categorical(y_resampled)#da mettere se uso model_flat()\n",
    "    return(X_resampled, y_resampled)\n",
    "train_generator_flow = train_img_pro.flow((x_train.reshape(x_train.shape[0],x_train.shape[1],1,1), y_train), \n",
    "                    batch_size=5000,\n",
    "                    shuffle=False #riordino i dati in maniera casuale\n",
    "                    )   \n",
    "train_generator_bal = balanced_flow_from_directory(train_generator_flow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ottimizzazione modello 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM\n",
    "def create_model(ass, fit = False):\n",
    "\n",
    "    keras_model = Sequential()\n",
    "    embedding_layer = Embedding(len(word_index)+1, 200,weights=[embedding_matrix],\n",
    "                               input_length=100, trainable = False)\n",
    "    keras_model.add(embedding_layer)\n",
    "    keras_model.add(Conv1D(32, 10, activation='relu', padding='same', strides=1,kernel_initializer='glorot_normal'))\n",
    "    keras_model.add(MaxPool1D())\n",
    "    keras_model.add(Conv1D(64, 10, activation='relu', padding='same', strides=1,kernel_initializer='glorot_normal'))\n",
    "    keras_model.add(MaxPool1D(pool_size=1))\n",
    "    keras_model.add(Dropout(ass[\"Dropout1\"]))\n",
    "    keras_model.add(Conv1D(128, 5, activation='relu', padding='same', strides=1,kernel_initializer='glorot_normal'))\n",
    "    keras_model.add(MaxPool1D(pool_size=4))\n",
    "    #keras_model.add(Flatten())\n",
    "    keras_model.add(LSTM(ass[\"lstm\"],kernel_regularizer = l1_l2(l1=0.01, l2=0.01)))\n",
    "    keras_model.add(Dense(ass[\"neuron\"], activation = \"relu\",kernel_regularizer = l1_l2(l1=0.1, l2=0.01)))\n",
    "    # keras_model.add(Dense(32, activation = \"relu\",kernel_regularizer = l1_l2(l1=0.1, l2=0.01))) #kernel_regularizer = l1_l2(l1=0.1, l2=0.01)\n",
    "    keras_model.add(Dropout(ass[\"Dropout2\"]))\n",
    "    keras_model.add(Dense(2, activation = \"softmax\"))\n",
    "    opt = ks.optimizers.Nadam(lr=ass[\"lr\"], beta_1=0.9, beta_2=0.99)\n",
    "    keras_model.compile(loss='categorical_crossentropy', metrics=['acc'], optimizer=opt)\n",
    "    if fit == True: \n",
    "        keras_model.fit_generator(generator=train_generator_bal,epochs=50, verbose= 1,steps_per_epoch = 200)#,class_weight=sample_weights)\n",
    "    return keras_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "def evaluate_test(x):\n",
    "    prediz = x.predict(x_val).argmax(axis = -1)\n",
    "    prediz_train = x.predict(x_train).argmax(axis = -1)\n",
    "    f1 = f1_score(y_val.argmax(axis = -1), prediz)\n",
    "    acc_train = accuracy_score(y_train.argmax(axis = -1), prediz_train)\n",
    "    acc_test = accuracy_score(y_val.argmax(axis = -1), prediz)\n",
    "    loss = 1/(1+abs(acc_train - acc_test))\n",
    "    loss_tot = loss + f1\n",
    "    return loss_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sigopt import Connection\n",
    "conn = Connection(client_token=\"IXACCJUXJAOPJVQJMVVZFLALEKTVAPQQPKLGNRQONZELZTBP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment = conn.experiments().create(\n",
    "#     name=\"Cnn-lstm-f1_acc\", parameters=[\n",
    "#         dict(name=\"lstm\", bounds=dict(min=30, max=500),type=\"int\"),\n",
    "#         dict(name=\"neuron\", bounds=dict(min=32, max=512),type=\"int\"),\n",
    "#         dict(name=\"lr\", bounds=dict(min=0.0005, max=0.1),type=\"double\"),\n",
    "#         dict(name = \"Dropout1\", bounds = dict(min = 0, max = 0.85), type = \"double\"),\n",
    "#         dict(name = \"Dropout2\", bounds = dict(min = 0, max = 0.85), type = \"double\")],\n",
    "#     observation_budget=25,\n",
    "#     project=\"text-mining\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = conn.experiments('154960').update(observation_budget=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(experiment.observation_budget):\n",
    "    suggestion = conn.experiments(experiment.id).suggestions().create()\n",
    "    assignments = suggestion.assignments\n",
    "    model = create_model(assignments)\n",
    "    f1 = evaluate_test(model)\n",
    "    model.save_weights('C:/Users/loren/text_mining_project/weights/modello_cnn_lstm/{}.h5'.format(f1))\n",
    "    conn.experiments(experiment.id).observations().create(\n",
    "        suggestion=suggestion.id,\n",
    "        value=f1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer weight shape (140201, 200) not compatible with provided weight shape (184884, 200)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-106-054682f69cff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mbest_assignments\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperiments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_assignments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massignments\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mbest_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_assignments\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-99-ba4cb8d6c0a4>\u001b[0m in \u001b[0;36mcreate_model\u001b[1;34m(ass, fit)\u001b[0m\n\u001b[0;32m      4\u001b[0m     embedding_layer = Embedding(len(word_index)+1, 200,weights=[embedding_matrix],\n\u001b[0;32m      5\u001b[0m                                input_length=100, trainable = False)\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mkeras_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membedding_layer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mkeras_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConv1D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'same'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkernel_initializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'glorot_normal'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mkeras_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMaxPool1D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    176\u001b[0m           \u001b[1;31m# and create the node connecting the current layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m           \u001b[1;31m# to the input layer we just created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m           \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m           \u001b[0mset_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    815\u001b[0m           \u001b[1;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m           \u001b[1;31m# overridden).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 817\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    818\u001b[0m           \u001b[0mcast_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    819\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2146\u001b[0m     \u001b[1;31m# Optionally load weight values specified at layer instantiation.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2147\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_initial_weights'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2148\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initial_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2149\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initial_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36mset_weights\u001b[1;34m(self, weights)\u001b[0m\n\u001b[0;32m   1334\u001b[0m         raise ValueError('Layer weight shape ' + str(ref_shape) +\n\u001b[0;32m   1335\u001b[0m                          \u001b[1;34m' not compatible with '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1336\u001b[1;33m                          'provided weight shape ' + str(w.shape))\n\u001b[0m\u001b[0;32m   1337\u001b[0m       \u001b[0mweight_value_tuples\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1338\u001b[0m     \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Layer weight shape (140201, 200) not compatible with provided weight shape (184884, 200)"
     ]
    }
   ],
   "source": [
    "best_assignments = conn.experiments(experiment.id).best_assignments().fetch().data[0].assignments\n",
    "best_model = create_model(best_assignments, fit = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.load_weights(\"C:/Users/loren/text_mining_project/weights/modello_cnn_lstm/1.720342497922431.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_pred = best_model.predict(x_val).argmax(axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     28801\n",
      "           1       0.89      0.94      0.91      3078\n",
      "\n",
      "    accuracy                           0.98     31879\n",
      "   macro avg       0.94      0.96      0.95     31879\n",
      "weighted avg       0.98      0.98      0.98     31879\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_val.argmax(axis = -1), acc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train = best_model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99    115305\n",
      "           1       0.89      0.94      0.91     12215\n",
      "\n",
      "    accuracy                           0.98    127520\n",
      "   macro avg       0.94      0.96      0.95    127520\n",
      "weighted avg       0.98      0.98      0.98    127520\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train.argmax(axis = -1), acc_train.argmax(axis = -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train = accuracy_score(y_train.argmax(axis = -1), acc_train.argmax(axis = -1))\n",
    "acc_test = accuracy_score(y_val.argmax(axis = -1),acc_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9130125262894275"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/(1+(abs(acc_train - acc_test))) + f1_score(y_val.argmax(axis = -1), acc_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9130982367758186"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_val.argmax(axis = -1), acc_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9825988080301129"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.982684525863421"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modello multi-input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input, LSTM\n",
    "from tensorflow.compat.v1.keras.layers import CuDNNLSTM\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\loren\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras_preprocessing\\text.py:178: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
      "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n"
     ]
    }
   ],
   "source": [
    "tokenizer2 = Tokenizer(nb_words=20)\n",
    "tokenizer2.fit_on_texts(df['less_pos'].astype(str))\n",
    "sequences_pos = tokenizer2.texts_to_sequences(df['less_pos'].astype(str))\n",
    "\n",
    "len(max(sequences_pos, key = len))\n",
    "\n",
    "len(min(sequences_pos, key = len))\n",
    "\n",
    "lengths = [len(i) for i in sequences_pos]\n",
    "\n",
    "data_pos = pad_sequences(sequences_pos, maxlen=100)\n",
    "\n",
    "data_pos = data_pos[indices]\n",
    "# labels = labels[indices]\n",
    "x_train_pos = data_pos[:-nb_validation_samples]\n",
    "# y_train = labels[:-nb_validation_samples]\n",
    "x_val_pos = data_pos[-nb_validation_samples:]\n",
    "# y_val = labels[-nb_validation_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_generator = np.concatenate([x_train, x_train_pos], axis = 1)\n",
    "input_generator = input_generator.reshape(input_generator.shape[0], input_generator.shape[1],1,1)\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "def balanced_flow_from_directory(flow_from_directory):\n",
    "    for immagini, classi in flow_from_directory:\n",
    "         yield custom_balance(np.squeeze(immagini),classi)\n",
    "            \n",
    "def custom_balance(X, y):\n",
    "    rus = RandomUnderSampler()\n",
    "    X_resampled, y_resampled = rus.fit_sample(X, y.argmax(axis = -1))     \n",
    "    #X_resampled, y_resampled = shuffle(X_resampled, y_resampled)\n",
    "    #y_resampled = y_resampled.reshape(y_resampled.shape[0], 1, 1, 1) #da mettere se uso model_conv()\n",
    "    y_resampled = to_categorical(y_resampled)#da mettere se uso model_flat()\n",
    "    return([X_resampled[:,0:100],np.expand_dims(X_resampled[:,100:],-1)] , y_resampled)\n",
    "\n",
    "train_generator_flow = train_img_pro.flow((input_generator, y_train), \n",
    "                    batch_size=3000,\n",
    "                    shuffle=False #riordino i dati in maniera casuale\n",
    "                    )   \n",
    "train_generator_bal = balanced_flow_from_directory(train_generator_flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model2(ass, fit = True):\n",
    "    \n",
    "    input_pos =Input(shape=(100,1), name = \"Input_pos\")\n",
    "    input_embed = Input(shape = (100), name = \"Input_embedding\")\n",
    "\n",
    "    embedding_layer = Embedding(len(word_index)+1, 200,weights=[embedding_matrix],\n",
    "                               input_length=100, trainable = False)(input_embed)\n",
    "    x = Conv1D(50, 32, activation='relu', padding='same', strides=1,kernel_initializer='glorot_normal')(embedding_layer)\n",
    "    x = MaxPooling1D()(x)\n",
    "    x = Conv1D(50, 16, activation='relu', padding='same', strides=1,kernel_initializer='glorot_normal')(x)\n",
    "    x = MaxPooling1D(pool_size = 1)(x)\n",
    "    x = Dropout(ass[\"Dropout1\"])(x)\n",
    "    x = Conv1D(16, 8, activation='relu', padding='same', strides=1,kernel_initializer='glorot_normal')(x)\n",
    "    x = MaxPooling1D(pool_size = 4)(x)  \n",
    "    x = CuDNNLSTM(ass[\"lstm\"], kernel_regularizer=l1_l2(l1 = 0.01, l2 = 0.01))(x)\n",
    "    aux_output = Dropout(ass[\"Dropout2\"])(x)\n",
    "    #x = Flatten()(x)\n",
    "    #aux_output = Dense(128, activation='relu')(x)\n",
    "    # preds = Dense(2, activation='softmax')(x)\n",
    "\n",
    "    model=CuDNNLSTM(ass[\"lstm2\"],kernel_initializer='glorot_normal')(input_pos)\n",
    "    model = Dropout(ass[\"Dropout3\"])(model)\n",
    "    #model = Dense(64, activation = \"relu\")(model)\n",
    "    aux_output2 = Dense(ass[\"dense1\"],activation = \"relu\",kernel_initializer='glorot_normal',kernel_regularizer = l1_l2(l1=0.01, l2=0.01))(model)\n",
    "\n",
    "    main_out = tensorflow.keras.backend.concatenate([aux_output,aux_output2])\n",
    "    main_out = Dense(ass[\"dense2\"], activation = \"relu\",kernel_initializer='glorot_normal',kernel_regularizer = l1_l2(l1=0.001, l2=0.001))(main_out)\n",
    "    main_out = Dense(2, activation = \"softmax\", name = \"output_totale\")(main_out)\n",
    "\n",
    "    model_tot = Model(inputs = [input_embed, input_pos], outputs = main_out)\n",
    "    \n",
    "    opt = ks.optimizers.Nadam(lr=0.01, beta_1=0.9, beta_2=0.99)\n",
    "    \n",
    "    model_tot.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "    if fit == True:\n",
    "        model_tot.fit_generator(train_generator_bal, steps_per_epoch=200, epochs=32)\n",
    "    \n",
    "    return model_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "def evaluate_test(x):\n",
    "    prediz = x.predict([x_val.astype(\"float32\"), np.expand_dims(x_val_pos.astype(\"float32\"),-1)]).argmax(axis = -1)\n",
    "    prediz_train = x.predict([x_train.astype(\"float32\"), np.expand_dims(x_train_pos.astype(\"float32\"), -1)]).argmax(axis = -1)\n",
    "    f1 = f1_score(y_val.argmax(axis = -1), prediz)\n",
    "    acc_train = accuracy_score(y_train.argmax(axis = -1), prediz_train)\n",
    "    acc_test = accuracy_score(y_val.argmax(axis = -1), prediz)\n",
    "    loss = 1/(1+abs(acc_train - acc_test))\n",
    "    loss_tot = loss + f1\n",
    "    return loss_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = conn.experiments().create(\n",
    "    name=\"Cnn-lstm-Pos_f1_acc\", parameters=[\n",
    "        dict(name=\"lstm\", bounds=dict(min=30, max=500),type=\"int\"),\n",
    "        dict(name=\"lstm2\", bounds=dict(min=30, max=500),type=\"int\"),\n",
    "        dict(name = \"dense1\", bounds=dict(min=32, max=512),type=\"int\"),\n",
    "        dict(name = \"dense2\", bounds=dict(min=32, max=512),type=\"int\"),\n",
    "        #dict(name=\"lr\", bounds=dict(min=0.01, max=0.1),type=\"double\"),\n",
    "        dict(name = \"Dropout1\", bounds = dict(min = 0, max = 0.85), type = \"double\"),\n",
    "        dict(name = \"Dropout2\", bounds = dict(min = 0, max = 0.85), type = \"double\"),\n",
    "    dict(name = \"Dropout3\", bounds = dict(min = 0, max = 0.85), type = \"double\")],\n",
    "    observation_budget=30,\n",
    "    project=\"text-mining\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = conn.experiments('155992').update(observation_budget=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "200/200 [==============================] - 88s 441ms/step - loss: 2.6140 - accuracy: 0.4996\n",
      "Epoch 2/32\n",
      "200/200 [==============================] - 94s 468ms/step - loss: 2.2870 - accuracy: 0.5555\n",
      "Epoch 3/32\n",
      "200/200 [==============================] - 88s 442ms/step - loss: 1.7589 - accuracy: 0.8595\n",
      "Epoch 4/32\n",
      "200/200 [==============================] - 99s 494ms/step - loss: 1.6062 - accuracy: 0.9030\n",
      "Epoch 5/32\n",
      "200/200 [==============================] - 96s 481ms/step - loss: 1.5296 - accuracy: 0.9312\n",
      "Epoch 6/32\n",
      "200/200 [==============================] - 80s 398ms/step - loss: 1.4758 - accuracy: 0.9442\n",
      "Epoch 7/32\n",
      "200/200 [==============================] - 77s 385ms/step - loss: 1.4855 - accuracy: 0.9490\n",
      "Epoch 8/32\n",
      "200/200 [==============================] - 74s 372ms/step - loss: 1.3710 - accuracy: 0.9641\n",
      "Epoch 9/32\n",
      "200/200 [==============================] - 75s 375ms/step - loss: 1.4054 - accuracy: 0.9639\n",
      "Epoch 10/32\n",
      "200/200 [==============================] - 78s 391ms/step - loss: 1.3099 - accuracy: 0.9714\n",
      "Epoch 11/32\n",
      "200/200 [==============================] - 75s 373ms/step - loss: 1.2830 - accuracy: 0.9732\n",
      "Epoch 12/32\n",
      "200/200 [==============================] - 81s 403ms/step - loss: 1.2635 - accuracy: 0.9739\n",
      "Epoch 13/32\n",
      "200/200 [==============================] - 75s 374ms/step - loss: 1.2185 - accuracy: 0.9779\n",
      "Epoch 14/32\n",
      "200/200 [==============================] - 79s 396ms/step - loss: 1.2066 - accuracy: 0.9784\n",
      "Epoch 15/32\n",
      "200/200 [==============================] - 80s 400ms/step - loss: 1.2026 - accuracy: 0.9805\n",
      "Epoch 16/32\n",
      "200/200 [==============================] - 72s 359ms/step - loss: 1.1626 - accuracy: 0.9809\n",
      "Epoch 17/32\n",
      "200/200 [==============================] - 91s 454ms/step - loss: 1.1324 - accuracy: 0.9826\n",
      "Epoch 18/32\n",
      "200/200 [==============================] - 107s 535ms/step - loss: 1.1314 - accuracy: 0.9817\n",
      "Epoch 19/32\n",
      "200/200 [==============================] - 93s 466ms/step - loss: 1.1155 - accuracy: 0.9850\n",
      "Epoch 20/32\n",
      "200/200 [==============================] - 90s 448ms/step - loss: 1.1182 - accuracy: 0.9834\n",
      "Epoch 21/32\n",
      "200/200 [==============================] - 80s 400ms/step - loss: 1.1306 - accuracy: 0.9853\n",
      "Epoch 22/32\n",
      "200/200 [==============================] - 29s 144ms/step - loss: 1.0571 - accuracy: 0.9849\n",
      "Epoch 23/32\n",
      "200/200 [==============================] - 29s 144ms/step - loss: 1.0221 - accuracy: 0.9871\n",
      "Epoch 24/32\n",
      "200/200 [==============================] - 29s 146ms/step - loss: 1.0309 - accuracy: 0.9871\n",
      "Epoch 25/32\n",
      "200/200 [==============================] - 27s 137ms/step - loss: 1.0309 - accuracy: 0.9866\n",
      "Epoch 26/32\n",
      "200/200 [==============================] - 28s 139ms/step - loss: 0.9944 - accuracy: 0.9872\n",
      "Epoch 27/32\n",
      "200/200 [==============================] - 29s 144ms/step - loss: 0.9895 - accuracy: 0.9874\n",
      "Epoch 28/32\n",
      "200/200 [==============================] - 29s 147ms/step - loss: 0.9823 - accuracy: 0.9855\n",
      "Epoch 29/32\n",
      "200/200 [==============================] - 29s 145ms/step - loss: 1.0212 - accuracy: 0.9871\n",
      "Epoch 30/32\n",
      "200/200 [==============================] - 29s 144ms/step - loss: 1.0367 - accuracy: 0.9881\n",
      "Epoch 31/32\n",
      "200/200 [==============================] - 29s 144ms/step - loss: 1.0926 - accuracy: 0.9886\n",
      "Epoch 32/32\n",
      "200/200 [==============================] - 29s 147ms/step - loss: 1.0447 - accuracy: 0.9888\n",
      "Epoch 1/32\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 2.1198 - accuracy: 0.7609\n",
      "Epoch 2/32\n",
      "200/200 [==============================] - 26s 131ms/step - loss: 1.4254 - accuracy: 0.8408\n",
      "Epoch 3/32\n",
      "200/200 [==============================] - 29s 146ms/step - loss: 1.3751 - accuracy: 0.8493\n",
      "Epoch 4/32\n",
      "200/200 [==============================] - 27s 135ms/step - loss: 1.3739 - accuracy: 0.8548\n",
      "Epoch 5/32\n",
      "200/200 [==============================] - 27s 137ms/step - loss: 1.3222 - accuracy: 0.8577\n",
      "Epoch 6/32\n",
      "200/200 [==============================] - 27s 137ms/step - loss: 1.3647 - accuracy: 0.8345\n",
      "Epoch 7/32\n",
      "200/200 [==============================] - 27s 135ms/step - loss: 1.3542 - accuracy: 0.8450\n",
      "Epoch 8/32\n",
      "200/200 [==============================] - 27s 133ms/step - loss: 1.3389 - accuracy: 0.8420\n",
      "Epoch 9/32\n",
      "200/200 [==============================] - 27s 133ms/step - loss: 1.3297 - accuracy: 0.8178\n",
      "Epoch 10/32\n",
      "200/200 [==============================] - 27s 134ms/step - loss: 1.3445 - accuracy: 0.8195\n",
      "Epoch 11/32\n",
      "200/200 [==============================] - 27s 137ms/step - loss: 1.3287 - accuracy: 0.8231\n",
      "Epoch 12/32\n",
      "200/200 [==============================] - 29s 147ms/step - loss: 1.3323 - accuracy: 0.7996\n",
      "Epoch 13/32\n",
      "200/200 [==============================] - 27s 134ms/step - loss: 1.3262 - accuracy: 0.7839\n",
      "Epoch 14/32\n",
      "200/200 [==============================] - 27s 137ms/step - loss: 1.2670 - accuracy: 0.8196\n",
      "Epoch 15/32\n",
      "200/200 [==============================] - 27s 136ms/step - loss: 1.3383 - accuracy: 0.7673\n",
      "Epoch 16/32\n",
      "200/200 [==============================] - 28s 140ms/step - loss: 1.2666 - accuracy: 0.8152\n",
      "Epoch 17/32\n",
      "200/200 [==============================] - 28s 140ms/step - loss: 1.2064 - accuracy: 0.8388\n",
      "Epoch 18/32\n",
      "200/200 [==============================] - 27s 137ms/step - loss: 1.1753 - accuracy: 0.8288\n",
      "Epoch 19/32\n",
      "200/200 [==============================] - 28s 139ms/step - loss: 1.1818 - accuracy: 0.8257\n",
      "Epoch 20/32\n",
      "200/200 [==============================] - 27s 133ms/step - loss: 1.1827 - accuracy: 0.8172\n",
      "Epoch 21/32\n",
      "200/200 [==============================] - 26s 132ms/step - loss: 1.2141 - accuracy: 0.8257\n",
      "Epoch 22/32\n",
      "200/200 [==============================] - 26s 132ms/step - loss: 1.1530 - accuracy: 0.8472\n",
      "Epoch 23/32\n",
      "200/200 [==============================] - 27s 133ms/step - loss: 1.1086 - accuracy: 0.8523\n",
      "Epoch 24/32\n",
      "200/200 [==============================] - 27s 133ms/step - loss: 1.1562 - accuracy: 0.8295\n",
      "Epoch 25/32\n",
      "200/200 [==============================] - 27s 133ms/step - loss: 1.1454 - accuracy: 0.8335\n",
      "Epoch 26/32\n",
      "200/200 [==============================] - 27s 133ms/step - loss: 1.0886 - accuracy: 0.8542\n",
      "Epoch 27/32\n",
      "200/200 [==============================] - 27s 134ms/step - loss: 1.1264 - accuracy: 0.8256\n",
      "Epoch 28/32\n",
      "200/200 [==============================] - 28s 138ms/step - loss: 1.1282 - accuracy: 0.8338\n",
      "Epoch 29/32\n",
      "200/200 [==============================] - 27s 136ms/step - loss: 1.1353 - accuracy: 0.8339\n",
      "Epoch 30/32\n",
      "200/200 [==============================] - 29s 144ms/step - loss: 1.1664 - accuracy: 0.8007\n",
      "Epoch 31/32\n",
      "200/200 [==============================] - 27s 133ms/step - loss: 1.1558 - accuracy: 0.7891\n",
      "Epoch 32/32\n",
      "200/200 [==============================] - 27s 133ms/step - loss: 1.1100 - accuracy: 0.8179\n",
      "Epoch 1/32\n",
      "200/200 [==============================] - 148s 738ms/step - loss: 2.1674 - accuracy: 0.7439\n",
      "Epoch 2/32\n",
      "200/200 [==============================] - 27s 134ms/step - loss: 1.3322 - accuracy: 0.8798\n",
      "Epoch 3/32\n",
      "200/200 [==============================] - 26s 131ms/step - loss: 1.2432 - accuracy: 0.9108\n",
      "Epoch 4/32\n",
      "200/200 [==============================] - 27s 134ms/step - loss: 1.2405 - accuracy: 0.9179\n",
      "Epoch 5/32\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 1.1697 - accuracy: 0.9360\n",
      "Epoch 6/32\n",
      "200/200 [==============================] - 26s 131ms/step - loss: 1.1016 - accuracy: 0.9453\n",
      "Epoch 7/32\n",
      "200/200 [==============================] - 26s 132ms/step - loss: 1.0671 - accuracy: 0.9522\n",
      "Epoch 8/32\n",
      "200/200 [==============================] - 27s 133ms/step - loss: 1.0379 - accuracy: 0.9568\n",
      "Epoch 9/32\n",
      "200/200 [==============================] - 26s 132ms/step - loss: 1.0051 - accuracy: 0.9604\n",
      "Epoch 10/32\n",
      "200/200 [==============================] - 27s 134ms/step - loss: 0.9769 - accuracy: 0.9637\n",
      "Epoch 11/32\n",
      "200/200 [==============================] - 27s 133ms/step - loss: 0.9534 - accuracy: 0.9663\n",
      "Epoch 12/32\n",
      "200/200 [==============================] - 27s 134ms/step - loss: 0.9390 - accuracy: 0.9683\n",
      "Epoch 13/32\n",
      "200/200 [==============================] - 28s 138ms/step - loss: 0.9143 - accuracy: 0.9706\n",
      "Epoch 14/32\n",
      "200/200 [==============================] - 27s 137ms/step - loss: 0.8980 - accuracy: 0.9727\n",
      "Epoch 15/32\n",
      "200/200 [==============================] - 27s 135ms/step - loss: 0.8746 - accuracy: 0.9718\n",
      "Epoch 16/32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 27s 134ms/step - loss: 0.8587 - accuracy: 0.9739\n",
      "Epoch 17/32\n",
      "200/200 [==============================] - 27s 135ms/step - loss: 0.8455 - accuracy: 0.9752\n",
      "Epoch 18/32\n",
      "200/200 [==============================] - 28s 142ms/step - loss: 0.8212 - accuracy: 0.9771\n",
      "Epoch 19/32\n",
      "200/200 [==============================] - 28s 139ms/step - loss: 0.8101 - accuracy: 0.9772\n",
      "Epoch 20/32\n",
      "200/200 [==============================] - 27s 133ms/step - loss: 0.7977 - accuracy: 0.9783\n",
      "Epoch 21/32\n",
      "200/200 [==============================] - 28s 138ms/step - loss: 0.8082 - accuracy: 0.9764\n",
      "Epoch 22/32\n",
      "200/200 [==============================] - 28s 142ms/step - loss: 0.7630 - accuracy: 0.9788\n",
      "Epoch 23/32\n",
      "200/200 [==============================] - 27s 137ms/step - loss: 0.7573 - accuracy: 0.9794\n",
      "Epoch 24/32\n",
      "200/200 [==============================] - 27s 133ms/step - loss: 0.7362 - accuracy: 0.9802\n",
      "Epoch 25/32\n",
      "200/200 [==============================] - 27s 134ms/step - loss: 0.7478 - accuracy: 0.9801\n",
      "Epoch 26/32\n",
      "200/200 [==============================] - 28s 140ms/step - loss: 0.7218 - accuracy: 0.9818\n",
      "Epoch 27/32\n",
      "200/200 [==============================] - 28s 141ms/step - loss: 0.7128 - accuracy: 0.9809\n",
      "Epoch 28/32\n",
      "200/200 [==============================] - 27s 135ms/step - loss: 0.7145 - accuracy: 0.9804\n",
      "Epoch 29/32\n",
      "200/200 [==============================] - 27s 133ms/step - loss: 0.6902 - accuracy: 0.9799\n",
      "Epoch 30/32\n",
      "200/200 [==============================] - 27s 134ms/step - loss: 0.6856 - accuracy: 0.9810\n",
      "Epoch 31/32\n",
      "200/200 [==============================] - 26s 132ms/step - loss: 0.7007 - accuracy: 0.9802\n",
      "Epoch 32/32\n",
      "200/200 [==============================] - 26s 132ms/step - loss: 0.7002 - accuracy: 0.9795\n",
      "Epoch 1/32\n",
      "200/200 [==============================] - 34s 170ms/step - loss: 3.6313 - accuracy: 0.7287\n",
      "Epoch 2/32\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 2.2825 - accuracy: 0.8714\n",
      "Epoch 3/32\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 2.2018 - accuracy: 0.9050\n",
      "Epoch 4/32\n",
      "200/200 [==============================] - 31s 153ms/step - loss: 2.1356 - accuracy: 0.9238\n",
      "Epoch 5/32\n",
      "200/200 [==============================] - 30s 152ms/step - loss: 2.0640 - accuracy: 0.9402\n",
      "Epoch 6/32\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 2.0068 - accuracy: 0.9499\n",
      "Epoch 7/32\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 1.9404 - accuracy: 0.9587\n",
      "Epoch 8/32\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 1.9063 - accuracy: 0.9618\n",
      "Epoch 9/32\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 1.8493 - accuracy: 0.9633\n",
      "Epoch 10/32\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 1.8467 - accuracy: 0.9694\n",
      "Epoch 11/32\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 1.7611 - accuracy: 0.9726\n",
      "Epoch 12/32\n",
      "200/200 [==============================] - 33s 166ms/step - loss: 1.7601 - accuracy: 0.9735\n",
      "Epoch 13/32\n",
      "200/200 [==============================] - 33s 166ms/step - loss: 1.6990 - accuracy: 0.9743\n",
      "Epoch 14/32\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 1.6726 - accuracy: 0.9754\n",
      "Epoch 15/32\n",
      "200/200 [==============================] - 31s 157ms/step - loss: 1.6270 - accuracy: 0.9782\n",
      "Epoch 16/32\n",
      "200/200 [==============================] - 31s 157ms/step - loss: 1.6389 - accuracy: 0.9745\n",
      "Epoch 17/32\n",
      "200/200 [==============================] - 36s 181ms/step - loss: 1.5889 - accuracy: 0.9792\n",
      "Epoch 18/32\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 1.5643 - accuracy: 0.9799\n",
      "Epoch 19/32\n",
      "200/200 [==============================] - 31s 153ms/step - loss: 1.5250 - accuracy: 0.9818\n",
      "Epoch 20/32\n",
      "200/200 [==============================] - 30s 152ms/step - loss: 1.5131 - accuracy: 0.9819\n",
      "Epoch 21/32\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 1.4643 - accuracy: 0.9835\n",
      "Epoch 22/32\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 1.4868 - accuracy: 0.9838\n",
      "Epoch 23/32\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 1.4210 - accuracy: 0.9841\n",
      "Epoch 24/32\n",
      "200/200 [==============================] - 30s 152ms/step - loss: 1.4046 - accuracy: 0.9839\n",
      "Epoch 25/32\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 1.5259 - accuracy: 0.9825\n",
      "Epoch 26/32\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 1.4369 - accuracy: 0.9847\n",
      "Epoch 27/32\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 1.4450 - accuracy: 0.9843\n",
      "Epoch 28/32\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 1.4086 - accuracy: 0.9872\n",
      "Epoch 29/32\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 1.3927 - accuracy: 0.9868\n",
      "Epoch 30/32\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 1.4060 - accuracy: 0.9857\n",
      "Epoch 31/32\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 1.2945 - accuracy: 0.9862\n",
      "Epoch 32/32\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 1.2730 - accuracy: 0.9875\n",
      "Epoch 1/32\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 2.7037 - accuracy: 0.6948\n",
      "Epoch 2/32\n",
      "200/200 [==============================] - 28s 138ms/step - loss: 1.7440 - accuracy: 0.8739\n",
      "Epoch 3/32\n",
      "200/200 [==============================] - 28s 140ms/step - loss: 1.6943 - accuracy: 0.8994\n",
      "Epoch 4/32\n",
      "200/200 [==============================] - 28s 140ms/step - loss: 1.6222 - accuracy: 0.9173\n",
      "Epoch 5/32\n",
      "200/200 [==============================] - 28s 140ms/step - loss: 1.5604 - accuracy: 0.9329\n",
      "Epoch 6/32\n",
      "200/200 [==============================] - 28s 140ms/step - loss: 1.5029 - accuracy: 0.9456\n",
      "Epoch 7/32\n",
      "200/200 [==============================] - 28s 140ms/step - loss: 1.4612 - accuracy: 0.9531\n",
      "Epoch 8/32\n",
      "200/200 [==============================] - 28s 140ms/step - loss: 1.4204 - accuracy: 0.9595\n",
      "Epoch 9/32\n",
      "200/200 [==============================] - 28s 140ms/step - loss: 1.3850 - accuracy: 0.9616\n",
      "Epoch 10/32\n",
      "200/200 [==============================] - 28s 140ms/step - loss: 1.3286 - accuracy: 0.9679\n",
      "Epoch 11/32\n",
      "200/200 [==============================] - 28s 140ms/step - loss: 1.3125 - accuracy: 0.9687\n",
      "Epoch 12/32\n",
      "200/200 [==============================] - 28s 140ms/step - loss: 1.2813 - accuracy: 0.9692\n",
      "Epoch 13/32\n",
      "200/200 [==============================] - 28s 140ms/step - loss: 1.2494 - accuracy: 0.9719\n",
      "Epoch 14/32\n",
      "200/200 [==============================] - 28s 140ms/step - loss: 1.2487 - accuracy: 0.9740\n",
      "Epoch 15/32\n",
      "200/200 [==============================] - 28s 140ms/step - loss: 1.2121 - accuracy: 0.9773\n",
      "Epoch 16/32\n",
      "200/200 [==============================] - 28s 140ms/step - loss: 1.1827 - accuracy: 0.9780\n",
      "Epoch 17/32\n",
      "200/200 [==============================] - 28s 140ms/step - loss: 1.1733 - accuracy: 0.9777\n",
      "Epoch 18/32\n",
      "200/200 [==============================] - 28s 140ms/step - loss: 1.1333 - accuracy: 0.9808\n",
      "Epoch 19/32\n",
      "200/200 [==============================] - 28s 140ms/step - loss: 1.1529 - accuracy: 0.9797\n",
      "Epoch 20/32\n",
      "200/200 [==============================] - 28s 140ms/step - loss: 1.1040 - accuracy: 0.9818\n",
      "Epoch 21/32\n",
      "200/200 [==============================] - 29s 144ms/step - loss: 1.1251 - accuracy: 0.9821\n",
      "Epoch 22/32\n",
      "200/200 [==============================] - 29s 143ms/step - loss: 1.0775 - accuracy: 0.9827\n",
      "Epoch 23/32\n",
      "200/200 [==============================] - 29s 144ms/step - loss: 1.1509 - accuracy: 0.9828\n",
      "Epoch 24/32\n",
      "200/200 [==============================] - 28s 141ms/step - loss: 1.0492 - accuracy: 0.9839\n",
      "Epoch 25/32\n",
      "200/200 [==============================] - 29s 146ms/step - loss: 1.1152 - accuracy: 0.9834\n",
      "Epoch 26/32\n",
      "200/200 [==============================] - 29s 146ms/step - loss: 1.0295 - accuracy: 0.9839\n",
      "Epoch 27/32\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 1.0173 - accuracy: 0.9847\n",
      "Epoch 28/32\n",
      "200/200 [==============================] - 28s 140ms/step - loss: 1.0068 - accuracy: 0.9850\n",
      "Epoch 29/32\n",
      "200/200 [==============================] - 28s 142ms/step - loss: 1.0137 - accuracy: 0.9858\n",
      "Epoch 30/32\n",
      "200/200 [==============================] - 28s 140ms/step - loss: 0.9926 - accuracy: 0.9845\n",
      "Epoch 31/32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 28s 142ms/step - loss: 0.9734 - accuracy: 0.9853\n",
      "Epoch 32/32\n",
      "200/200 [==============================] - 29s 144ms/step - loss: 0.9539 - accuracy: 0.9861\n",
      "Epoch 1/32\n",
      "200/200 [==============================] - 97s 483ms/step - loss: 2.6168 - accuracy: 0.5059\n",
      "Epoch 2/32\n",
      "200/200 [==============================] - 28s 140ms/step - loss: 2.4332 - accuracy: 0.7496\n",
      "Epoch 3/32\n",
      "200/200 [==============================] - 28s 140ms/step - loss: 1.5501 - accuracy: 0.8738\n",
      "Epoch 4/32\n",
      "200/200 [==============================] - 27s 133ms/step - loss: 1.4942 - accuracy: 0.9000\n",
      "Epoch 5/32\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 1.4400 - accuracy: 0.9224\n",
      "Epoch 6/32\n",
      "200/200 [==============================] - 31s 153ms/step - loss: 1.3800 - accuracy: 0.9376\n",
      "Epoch 7/32\n",
      "200/200 [==============================] - 33s 167ms/step - loss: 1.3489 - accuracy: 0.9483\n",
      "Epoch 8/32\n",
      "200/200 [==============================] - 28s 138ms/step - loss: 1.3213 - accuracy: 0.9544\n",
      "Epoch 9/32\n",
      "200/200 [==============================] - 27s 137ms/step - loss: 1.3287 - accuracy: 0.9572\n",
      "Epoch 10/32\n",
      "200/200 [==============================] - 27s 134ms/step - loss: 1.2764 - accuracy: 0.9635\n",
      "Epoch 11/32\n",
      "200/200 [==============================] - 27s 134ms/step - loss: 1.2453 - accuracy: 0.9640\n",
      "Epoch 12/32\n",
      "200/200 [==============================] - 27s 134ms/step - loss: 1.2410 - accuracy: 0.9654\n",
      "Epoch 13/32\n",
      "200/200 [==============================] - 27s 135ms/step - loss: 1.2283 - accuracy: 0.9693\n",
      "Epoch 14/32\n",
      "200/200 [==============================] - 27s 134ms/step - loss: 1.2810 - accuracy: 0.9604\n",
      "Epoch 15/32\n",
      "200/200 [==============================] - 27s 133ms/step - loss: 1.1701 - accuracy: 0.9694\n",
      "Epoch 16/32\n",
      "200/200 [==============================] - 27s 134ms/step - loss: 1.2384 - accuracy: 0.9716\n",
      "Epoch 17/32\n",
      "200/200 [==============================] - 27s 133ms/step - loss: 1.3708 - accuracy: 0.9719\n",
      "Epoch 18/32\n",
      "200/200 [==============================] - 27s 135ms/step - loss: 1.2406 - accuracy: 0.9739\n",
      "Epoch 19/32\n",
      "200/200 [==============================] - 27s 136ms/step - loss: 1.2321 - accuracy: 0.9742\n",
      "Epoch 20/32\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 1.1431 - accuracy: 0.9751\n",
      "Epoch 21/32\n",
      "200/200 [==============================] - 30s 152ms/step - loss: 1.1827 - accuracy: 0.9749\n",
      "Epoch 22/32\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 1.1253 - accuracy: 0.9761\n",
      "Epoch 23/32\n",
      "200/200 [==============================] - 27s 137ms/step - loss: 1.1271 - accuracy: 0.9751\n",
      "Epoch 24/32\n",
      "200/200 [==============================] - 28s 141ms/step - loss: 1.1415 - accuracy: 0.9748\n",
      "Epoch 25/32\n",
      "200/200 [==============================] - 27s 137ms/step - loss: 1.1672 - accuracy: 0.9719\n",
      "Epoch 26/32\n",
      "200/200 [==============================] - 28s 139ms/step - loss: 1.1710 - accuracy: 0.9720\n",
      "Epoch 27/32\n",
      "200/200 [==============================] - 27s 134ms/step - loss: 1.1657 - accuracy: 0.9711\n",
      "Epoch 28/32\n",
      "200/200 [==============================] - 27s 133ms/step - loss: 1.1639 - accuracy: 0.9705\n",
      "Epoch 29/32\n",
      "200/200 [==============================] - 27s 134ms/step - loss: 1.1625 - accuracy: 0.9717\n",
      "Epoch 30/32\n",
      "200/200 [==============================] - 27s 135ms/step - loss: 1.2716 - accuracy: 0.9686\n",
      "Epoch 31/32\n",
      "200/200 [==============================] - 28s 139ms/step - loss: 1.1913 - accuracy: 0.9701\n",
      "Epoch 32/32\n",
      "200/200 [==============================] - 31s 155ms/step - loss: 1.1988 - accuracy: 0.9676\n",
      "Epoch 1/32\n",
      " 17/200 [=>............................] - ETA: 42s - loss: 10.7205 - accuracy: 0.5010"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[128] and type int8 on /job:localhost/replica:0/task:0/device:GPU:0 by allocator gpu_host_bfc [Op:ConcatV2] name: concat",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-104038044c31>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0msuggestion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperiments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuggestions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0massignments\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuggestion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massignments\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_model2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0massignments\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mf1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:/Users/loren/text_mining_project/weights/modello_cnn_lstm_pos/{}.h5'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-27-c0b83ed6798d>\u001b[0m in \u001b[0;36mcreate_model2\u001b[1;34m(ass)\u001b[0m\n\u001b[0;32m     35\u001b[0m               \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m               metrics=['accuracy'])\n\u001b[1;32m---> 37\u001b[1;33m     \u001b[0mmodel_tot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_generator_bal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel_tot\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1295\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1296\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1297\u001b[1;33m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m   1298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1299\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m       \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m    971\u001b[0m       outputs = training_v2_utils.train_on_batch(\n\u001b[0;32m    972\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m           class_weight=class_weight, reset_metrics=reset_metrics)\n\u001b[0m\u001b[0;32m    974\u001b[0m       outputs = (outputs['total_loss'] + outputs['output_losses'] +\n\u001b[0;32m    975\u001b[0m                  outputs['metrics'])\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(model, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m    262\u001b[0m       \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m       \u001b[0msample_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m       output_loss_metrics=model._output_loss_metrics)\n\u001b[0m\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_eager.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(model, inputs, targets, sample_weights, output_loss_metrics)\u001b[0m\n\u001b[0;32m    309\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m           \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 311\u001b[1;33m           output_loss_metrics=output_loss_metrics))\n\u001b[0m\u001b[0;32m    312\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_eager.py\u001b[0m in \u001b[0;36m_process_single_batch\u001b[1;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[0;32m    250\u001b[0m               \u001b[0moutput_loss_metrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_loss_metrics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m               \u001b[0msample_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m               training=training))\n\u001b[0m\u001b[0;32m    253\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m         raise ValueError('The model cannot be run '\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_eager.py\u001b[0m in \u001b[0;36m_model_loss\u001b[1;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[0;32m    125\u001b[0m     \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m   \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m   \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[0;32m    890\u001b[0m               self._compute_dtype):\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    706\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m    707\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 708\u001b[1;33m         convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n\u001b[0m\u001b[0;32m    709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[1;34m(self, inputs, training, mask, convert_kwargs_to_constants)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m           \u001b[1;31m# Compute outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 860\u001b[1;33m           \u001b[0moutput_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomputed_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m           \u001b[1;31m# Update tensor_dict.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[0;32m    621\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 623\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    624\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    625\u001b[0m     \u001b[1;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[0;32m    890\u001b[0m               self._compute_dtype):\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\cudnn_recurrent.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[0;32m    108\u001b[0m       \u001b[1;31m# Reverse time axis.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m       \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m     \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\cudnn_recurrent.py\u001b[0m in \u001b[0;36m_process_batch\u001b[1;34m(self, inputs, initial_state)\u001b[0m\n\u001b[0;32m    494\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munits\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m         ],\n\u001b[1;32m--> 496\u001b[1;33m         shape=self._vector_shape)\n\u001b[0m\u001b[0;32m    497\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m     args = {\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\recurrent_v2.py\u001b[0m in \u001b[0;36m_canonical_to_params\u001b[1;34m(weights, biases, shape, transpose_weights)\u001b[0m\n\u001b[0;32m   1016\u001b[0m   \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1017\u001b[0m   \u001b[0mbiases\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbiases\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1018\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mbiases\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1019\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1020\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_core\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(values, axis, name)\u001b[0m\n\u001b[0;32m   1429\u001b[0m           dtype=dtypes.int32).get_shape().assert_has_rank(0)\n\u001b[0;32m   1430\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0midentity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1431\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1432\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mconcat_v2\u001b[1;34m(values, axis, name)\u001b[0m\n\u001b[0;32m   1247\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1248\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1249\u001b[1;33m       \u001b[0m_six\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1250\u001b[0m   \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1251\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[128] and type int8 on /job:localhost/replica:0/task:0/device:GPU:0 by allocator gpu_host_bfc [Op:ConcatV2] name: concat"
     ]
    }
   ],
   "source": [
    "for _ in range(experiment.observation_budget):\n",
    "    suggestion = conn.experiments(experiment.id).suggestions().create()\n",
    "    assignments = suggestion.assignments\n",
    "    model = create_model2(assignments)\n",
    "    f1 = evaluate_test(model)\n",
    "    model.save_weights('C:/Users/loren/text_mining_project/weights/modello_cnn_lstm_pos/{}.h5'.format(f1))\n",
    "    conn.experiments(experiment.id).observations().create(\n",
    "        suggestion=suggestion.id,\n",
    "        value=f1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": " Cannot parse tensor from proto: dtype: DT_INT32\ntensor_shape {\n}\nint_val: 1\n\n\t [[{{node Identity/_0__cf__135}}]] [Op:__inference_keras_scratch_graph_523483307]\n\nFunction call stack:\nkeras_scratch_graph\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-097899ac0888>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mbest_assignments\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperiments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_assignments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massignments\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mbest_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_model2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_assignments\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-31-2c6e98453a41>\u001b[0m in \u001b[0;36mcreate_model2\u001b[1;34m(ass, fit)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mmain_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maux_output\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maux_output2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[0mmain_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mass\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"dense2\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"relu\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkernel_initializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'glorot_normal'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkernel_regularizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ml1_l2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m     \u001b[0mmain_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"softmax\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"output_totale\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    793\u001b[0m     \u001b[1;31m# framework.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbuild_graph\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbase_layer_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneeds_keras_history\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m       \u001b[0mbase_layer_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_keras_history\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    796\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m     \u001b[1;31m# Clear eager losses on top level model call.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer_utils.py\u001b[0m in \u001b[0;36mcreate_keras_history\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    182\u001b[0m     \u001b[0mkeras_tensors\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mTensors\u001b[0m \u001b[0mfound\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mcame\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0ma\u001b[0m \u001b[0mKeras\u001b[0m \u001b[0mLayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m   \"\"\"\n\u001b[1;32m--> 184\u001b[1;33m   \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreated_layers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_create_keras_history_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    185\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mcreated_layers\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer_utils.py\u001b[0m in \u001b[0;36m_create_keras_history_helper\u001b[1;34m(tensors, processed_ops, created_layers)\u001b[0m\n\u001b[0;32m    227\u001b[0m           \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m               \u001b[0mconstants\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m       processed_ops, created_layers = _create_keras_history_helper(\n\u001b[0;32m    231\u001b[0m           layer_inputs, processed_ops, created_layers)\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3740\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3742\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1080\u001b[0m     \"\"\"\n\u001b[1;32m-> 1081\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1082\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1121\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m:  Cannot parse tensor from proto: dtype: DT_INT32\ntensor_shape {\n}\nint_val: 1\n\n\t [[{{node Identity/_0__cf__135}}]] [Op:__inference_keras_scratch_graph_523483307]\n\nFunction call stack:\nkeras_scratch_graph\n"
     ]
    }
   ],
   "source": [
    "best_assignments = conn.experiments(experiment.id).best_assignments().fetch().data[0].assignments\n",
    "best_model = create_model2(best_assignments, fit = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validazione inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"D:\\Datasets\\NLP_text_mining\\preprocessed_text_toxic2.csv\")\n",
    "test = pd.read_csv(r\"D:\\Datasets\\NLP_text_mining\\true_pos_toxic_final_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = pd.concat([df.text, test.text])\n",
    "all_labels = pd.concat([df.toxic, test.toxic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\loren\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras_preprocessing\\text.py:178: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
      "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 262524 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(nb_words=100000)\n",
    "tokenizer.fit_on_texts(all_text.astype(str))\n",
    "sequences = tokenizer.texts_to_sequences(all_text.astype(str))\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "data = pad_sequences(sequences, maxlen=100)\n",
    "\n",
    "labels = to_categorical(np.asarray(all_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx = len(df)\n",
    "\n",
    "x_train = data[:train_idx]\n",
    "y_train = labels[:train_idx]\n",
    "x_test = data[train_idx:]\n",
    "y_test = labels[train_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, 200))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "200/200 [==============================] - 34s 171ms/step - loss: 51.8526 - acc: 0.6945\n",
      "Epoch 2/50\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 1.3481 - acc: 0.7266\n",
      "Epoch 3/50\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 1.1244 - acc: 0.7495\n",
      "Epoch 4/50\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 1.0814 - acc: 0.7819\n",
      "Epoch 5/50\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 1.0440 - acc: 0.8124\n",
      "Epoch 6/50\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 1.0001 - acc: 0.8328\n",
      "Epoch 7/50\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.9586 - acc: 0.8563\n",
      "Epoch 8/50\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.9342 - acc: 0.8694\n",
      "Epoch 9/50\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.8940 - acc: 0.8882\n",
      "Epoch 10/50\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.8614 - acc: 0.8999\n",
      "Epoch 11/50\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.8518 - acc: 0.8988\n",
      "Epoch 12/50\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.8012 - acc: 0.9215\n",
      "Epoch 13/50\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.8027 - acc: 0.9258\n",
      "Epoch 14/50\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.7662 - acc: 0.9355\n",
      "Epoch 15/50\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.7431 - acc: 0.9385\n",
      "Epoch 16/50\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.7777 - acc: 0.9319\n",
      "Epoch 17/50\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.8552 - acc: 0.8433\n",
      "Epoch 18/50\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.7349 - acc: 0.9313\n",
      "Epoch 19/50\n",
      "200/200 [==============================] - 26s 130ms/step - loss: 0.6822 - acc: 0.9543\n",
      "Epoch 20/50\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.6571 - acc: 0.9598\n",
      "Epoch 21/50\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.6416 - acc: 0.9609\n",
      "Epoch 22/50\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.6157 - acc: 0.9659\n",
      "Epoch 23/50\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.5953 - acc: 0.9687\n",
      "Epoch 24/50\n",
      "200/200 [==============================] - 26s 130ms/step - loss: 0.5822 - acc: 0.9691\n",
      "Epoch 25/50\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.5692 - acc: 0.9706\n",
      "Epoch 26/50\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.5590 - acc: 0.9698\n",
      "Epoch 27/50\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.6470 - acc: 0.9368\n",
      "Epoch 28/50\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.5718 - acc: 0.9660\n",
      "Epoch 29/50\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.5845 - acc: 0.9556\n",
      "Epoch 30/50\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.5350 - acc: 0.9715\n",
      "Epoch 31/50\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.5092 - acc: 0.9763\n",
      "Epoch 32/50\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.5183 - acc: 0.9732\n",
      "Epoch 33/50\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.5015 - acc: 0.9738\n",
      "Epoch 34/50\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4954 - acc: 0.9767\n",
      "Epoch 35/50\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4719 - acc: 0.9792\n",
      "Epoch 36/50\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4644 - acc: 0.9790\n",
      "Epoch 37/50\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.4739 - acc: 0.9761\n",
      "Epoch 38/50\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.5416 - acc: 0.9614\n",
      "Epoch 39/50\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.4875 - acc: 0.9735\n",
      "Epoch 40/50\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4879 - acc: 0.9758\n",
      "Epoch 41/50\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.4204 - acc: 0.9841\n",
      "Epoch 42/50\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.4428 - acc: 0.9768\n",
      "Epoch 43/50\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 0.4668 - acc: 0.9762\n",
      "Epoch 44/50\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.4720 - acc: 0.9743\n",
      "Epoch 45/50\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.4143 - acc: 0.9836\n",
      "Epoch 46/50\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4011 - acc: 0.9849\n",
      "Epoch 47/50\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4247 - acc: 0.9812\n",
      "Epoch 48/50\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3971 - acc: 0.9842\n",
      "Epoch 49/50\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3966 - acc: 0.9820\n",
      "Epoch 50/50\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3890 - acc: 0.9840\n"
     ]
    }
   ],
   "source": [
    "best_assignments = conn.experiments(experiment.id).best_assignments().fetch().data[0].assignments\n",
    "best_model = create_model(best_assignments, fit = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.91    144106\n",
      "           1       0.17      0.16      0.17     15293\n",
      "\n",
      "    accuracy                           0.84    159399\n",
      "   macro avg       0.54      0.54      0.54    159399\n",
      "weighted avg       0.84      0.84      0.84    159399\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc_pred = best_model.predict(x_train).argmax(axis = -1)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_train.argmax(axis = -1), acc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91     57888\n",
      "           1       0.15      0.15      0.15      6090\n",
      "\n",
      "    accuracy                           0.83     63978\n",
      "   macro avg       0.53      0.53      0.53     63978\n",
      "weighted avg       0.84      0.83      0.84     63978\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc_pred = best_model.predict(x_test).argmax(axis = -1)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test.argmax(axis = -1), acc_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
